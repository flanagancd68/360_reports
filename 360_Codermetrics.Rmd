---
title: "Codermetrics"
output: html_notebook
---
title:
# "Codermetrics"
## Rethinking Coder success beyond accuracy and productivity
abstract:
The past several years have seen an exponential growth in the amount of data available in just about every field and discipline.
During the 20th century in baseball, a batter's success was measured on batting average and that was it.  Many analysts started to conclude that batting average alone was incomplete since it has no correlation to runs, and runs are what win ballbames. 
With the dawn of the 21st century, a new word started to weave its way into the fabric of the game: "Sabermetrics".  Sabermetrics refers to measuring and analyzing a seemingly countless number of baseball statistics.  For example, we can measure the distance, velocity, and even the launch angle of a batted ball.  This enables baseball statisticians and management to make determinations based on overall success of a player. There is now the concept of a "five-tool player", where batting average is just one of the five categories measured.
As coding operational or compliance leaders, we have a similarly explosive wealth of data on coder performance available within the 360 platform.  Join us for a lighthearted, interactive discussion on some new ways to meaasure a coder's success beyond accuracy and productivity.  During the discussion, we will explore how baseball's "five tools" might be applied to coder performance.   In other words, let's talk about "Codermetrics"!



## outcomes
baseball: k, bb, 1b, 2b, 3b, hr, hbp, reach on error, other types of outs
coding: DRG[MDC (1-24), MSDRG and/or APRDRG], SOI (1-4), ROM (1-4), on-hold

Unlike baseball, the main goal with coder metrics is not to award batting titles or send people to the minors, but to detect variation and help everyone improve
Are high outliers best in case examples or are they skimping on something
Are low outliers trainable, are there obstacles they have that others do not?


====


Player = coderTeam = hospital Division = GroupLeague = Company(Pitcher =  in the analogy, physician - but we don't want to 'go there' with docs as adversaries 0 At bat/plate appearance = final coded accountGame = day workedOut = sev 1 Los > gmlos for apr DRG  (soi+rom 1,2)single= sev 1 Los <= gmlos or sev 2 > gmlos (3)Double =  (4,5)
	* Sev 2 <= gmlos
	* sev 3 > gmlos

triple = (6)
	* Sev 3 <= gmlos

hr sev 4 (7,8)Runs = 2b, 3b, hrRunning - productivityStolen base = min/pt day <= Group average for DRG?Caught stealing = min/pt day > group avg for DRGFieldingPutout = using evidence view => 75%

===================

# Data Analysis Questions (<- belongs with 'codermetrics')

# There are six basic categories of questions^[Leek, "Types of Data Science Questions"]  
    1. Descriptive
        a. describe but not make decisions/interpret/infer
        b. How many coders / accounts / queries / codes?
        
    1. Exploratory
        a. look at data and find relationships
        b. drive future analysis to confirm
        c. __Are there any relationships between engine size and gas consumption?__
        c. not the final say - shouldn't be used for generalization or predicting
        d. __is it because big engines are heavier?  require a higher volume of fuel?__
        c. correlation is not causation
            - e.g. relationship between shoe size and intellect - the data shows that people with a size 2 are less intelligent than those with size 9.  People with a size 2 are also children where as size 9 are adults!
        e. **Are there any relationships between querying and severity?**
        
    2. Inferential
        a. take a small number of observations and extrapolate/generalize
        b. commonly the goal of statistical analysis - we want to draw conclusions
        
    3. Predictive
        a. More challenging - use data on some objects to predict value of another object
        b. just because x predicts y doesn't mean that x causes y
        c. "prediction is hard; especially about the future."
        d. Nate Silver examples of predicting US elections
    1. Casual
        a. if you change one value, will it change anothe?
        b. **if we improve P&R or the other metrics, will it improve ROI on CAC investement** (generally in terms of improved severity capture and coder productivity)?
        c. This is the **goal** of anlysis
    1. Mechanistic
        a. understand exact changes in variables that will lead to changes in other variables
        
- All the data in the world can't save you if you don't ask the right questions


#keys <- read_xlsx("./data/external/keys.xlsx")
#prterms <- read_xlsx("./data/external/prterms.xlsx")
#lowprecis <- read_xlsx("./data/external/lowprecis.xlsx")
#lowrecall <- read_xlsx("./data/external/lowrecall.xlsx")
===========
Chapter 1Let’s not be too sure that we haven’t been missing something important. Bill James  the metrics we commonly deal with don’t provide enough insight to answer many key questions that we have, such as:• How well is our software team succeeding?• How are individual team members contributing to the team’s success?• What capabilities can be improved to achieve greater success?How even do we define success?For hospitals we need to define winning and losing teams.  Then, Find a way to measure the differences between winning and losing teams.• Find a way to measure the contributions of individual players to their teams.• Determine key player characteristics that are highly correlated with winning or losing.Naturally we, like any workers, might be suspicious about whether good metrics can be found and tell an effective story, and we might be worried that statistics can be misused by managers in performance reviews and such. It is the premise of this book, however, that within our discipline there are a variety of skills and results that we can indeed measure, and from which we can obtain meaningful and useful insights about ourselves and our teams.This method is designed to challenge our assumptions, in hopes that we can better discover what is knowable about the patterns that lead to success. To make them easier to understand and remember, the metrics in this book are named after analogous sports statistics. These metrics are designed to give us some terminology to better communicate, and hopefully to make us think generally about how these types of metrics can be useful in our field. In the end, their value can be measured by how well they help us answer the key questions that we face as to what it means to “win” and how we can better ourselves and our teams.An outlier is more than an anomaly.  An outlier is consistently reproduced. Study outliers

CHAPTER 2- measuring what coders can do. Never mistake activity for achievement. John WoodenMetrics are not grades. Derek Jeter had some below average fielding metrics but hell be a first ballot hall of famer in 2020. We are trying to be fair.  Biggest thing is “my patients ARENT sicker”. So we look at things like per patient day (longer should equal sicker even though it is out of a coders control. Also per weight (1.0 of DRG weight) helps To normalize.   Use alos as proxy for complexity. 

Use stats to identify undervalued codersmetrics can directly contribute to a healthier environment if they are used to help the team improve and succeed—and if they result in better understanding of in- dividual contributions that might not have been fully appreciated before.T